{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os \n",
    "import random\n",
    "\n",
    "import tensorflow\n",
    "\n",
    "from keras.layers import Conv2D, UpSampling2D, Conv2DTranspose\n",
    "from keras.layers import Activation, Dense, Dropout,Flatten,InputLayer\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "from skimage.color import rgb2lab, lab2rgb, rgb2gray\n",
    "from skimage.io import imsave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n",
      "240\n",
      "250\n",
      "260\n",
      "270\n",
      "280\n",
      "290\n",
      "300\n",
      "310\n",
      "320\n",
      "330\n",
      "340\n",
      "350\n",
      "360\n",
      "370\n",
      "380\n",
      "390\n",
      "400\n"
     ]
    }
   ],
   "source": [
    "# Get images\n",
    "X = []\n",
    "number_of_files = 0\n",
    "for filename in os.listdir('Train'):\n",
    "    temporary_img = load_img('Train/'+filename)\n",
    "    temporary_img = img_to_array(temporary_img)\n",
    "    X.append(temporary_img) #add the image to the array.\n",
    "    number_of_files += 1 # count the number of files\n",
    "    if number_of_files % 10 == 0:\n",
    "        print(number_of_files) # print every 10th number\n",
    "    # load in just the first 400 images\n",
    "    # to help fight out of memory error.\n",
    "    if number_of_files - 400 == 0:\n",
    "        break\n",
    "# Convert standard array to numpy array for future\n",
    "X = np.array(X)#, dtype=float) #float gives error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up train and test data\n",
    "split = int(0.95 * len(X))\n",
    "# use 95% of the loaded dataset for training.\n",
    "Xtrain = X[:split]\n",
    "# divide the numbers in the array by 255\n",
    "# but keep them as float numbers (with 1.0)\n",
    "Xtrain = 1.0/255 * Xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the neural network\n",
    "model = Sequential()\n",
    "#256px by 256px is expected as input\n",
    "#and only lightness channel is given as input.\n",
    "model.add(InputLayer(input_shape=(256, 256, 1)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same', strides=2))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding='same', strides=2))\n",
    "model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(256, (3, 3), activation='relu', padding='same', strides=2))\n",
    "model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "model.add(UpSampling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "model.add(UpSampling2D((2, 2)))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(2, (3, 3), activation='tanh', padding='same'))\n",
    "model.add(UpSampling2D((2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image transformer\n",
    "# Rotate, flip, zoom in on pictures and etc so that\n",
    "# the training set becomes larger\n",
    "# improves the accurracy too!\n",
    "datagen = ImageDataGenerator(\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        rotation_range=20,\n",
    "        horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate training data\n",
    "def image_a_b_gen():\n",
    "    #for every picture: get its L and ab channels\n",
    "    #and save them for later\n",
    "    for batch in datagen.flow(Xtrain):#, batch_size=batch_size):\n",
    "        lab_batch = rgb2lab(batch)\n",
    "        X_batch = lab_batch[:,:,:,0] # get the lightness channel\n",
    "        Y_batch = lab_batch[:,:,:,1:] / 128\n",
    "        # yield is like return but it just keeps the variables\n",
    "        # in the memory, that way it doesn't stop the for loop on 1st\n",
    "        # loop.\n",
    "        yield (X_batch.reshape(X_batch.shape+(1,)), Y_batch)\n",
    "        # it might be the cause of the out of memory error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400\n",
      "(380, 256, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "#Debugging information, to ensure everything is set up correctly.\n",
    "print(number_of_files)\n",
    "print(Xtrain.shape) #number of files to train on,\n",
    "#the rest is left for testing and evaluating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "#tensorboard works on Manjaro, breaks on my laptop's windows 10.\n",
    "#tensorboard = TensorBoard(log_dir=\"output/current_run\")\n",
    "#tensorboard = [tensorboard]\n",
    "#model.fit(x=X,y=Y,batch_size=20,epochs=1)\n",
    "model.fit_generator(image_a_b_gen(),\n",
    "                   steps_per_epoch=3,\n",
    "                   epochs=1,use_multiprocessing=True)#, callbacks=tensorboard)\n",
    "                    #comment out use_multiprocessing on win10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model and its weights.\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "model.save_weights(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model using the test images\n",
    "# Get the lightness channel of an image.\n",
    "Xtest = rgb2lab(1.0/255*X[split:])[:,:,:,0]\n",
    "Xtest = Xtest.reshape(Xtest.shape+(1,))\n",
    "#Get the ab channels of the image.\n",
    "Ytest = rgb2lab(1.0/255*X[split:])[:,:,:,1:]\n",
    "# Normalise the data to be between -1 and 1.\n",
    "Ytest = Ytest / 128\n",
    "#print the model's accuracy.\n",
    "print(model.evaluate(Xtest, Ytest, batch_size=20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the images to be ran across the model's predictions.\n",
    "color_me = []\n",
    "for filename in os.listdir('Test/'):\n",
    "    color_me.append(img_to_array(load_img('Test/'+filename)))\n",
    "color_me = np.array(color_me, dtype=float)\n",
    "color_me = rgb2lab(1.0/255*color_me)[:,:,:,0]\n",
    "color_me = color_me.reshape(color_me.shape+(1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test model\n",
    "# Run the model through the prepared testing set.\n",
    "output = model.predict(color_me)\n",
    "#the values are between -1 and 1 so to restore the values of ab channels we need to multiply them by 128.\n",
    "output = output * 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Save the output\n",
    "#Add a module that does float64 to uint8 conversion for us\n",
    "from skimage import img_as_ubyte\n",
    "\n",
    "# Output colorizations\n",
    "for i in range(len(output)):\n",
    "    # Create an empty matrix that has 3 channels, each 256 x 256 in preparation of the final rgb picture.\n",
    "    create_image = np.zeros((256, 256, 3))\n",
    "    # Fill the first layer with the lightness channel information\n",
    "    create_image[:,:,0] = color_me[i][:,:,0]\n",
    "    #fill the 2nd and 3rd channel with produced output.\n",
    "    create_image[:,:,1:] = output[i]\n",
    "    \n",
    "    create_image = lab2rgb(create_image)\n",
    "    create_image = img_as_ubyte(create_image) #convert float64 to uint8 to avoid lossy conversion.\n",
    "    #print(output[i].max())\n",
    "    imsave(\"result/img_\"+str(i)+\".png\", create_image)\n",
    "    print(\"Saved picture number: \", i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
